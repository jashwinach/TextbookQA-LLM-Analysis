{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Generation using BLIP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from lavis.models import load_model_and_preprocess\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888a22b049b54ea082874a2b394902c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loads BLIP-2 pre-trained model\n",
    "model, vis_processors, _ = load_model_and_preprocess(name=\"blip2_t5\", model_type=\"pretrain_flant5xxl\", is_eval=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesson_name</th>\n",
       "      <th>question_name</th>\n",
       "      <th>answer_choice_1</th>\n",
       "      <th>answer_choice_2</th>\n",
       "      <th>answer_choice_3</th>\n",
       "      <th>answer_choice_4</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_has_labels_to_guess</th>\n",
       "      <th>caption</th>\n",
       "      <th>blip_2_generated_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate and its causes</td>\n",
       "      <td>Which label refers to rains?</td>\n",
       "      <td>V</td>\n",
       "      <td>T</td>\n",
       "      <td>U</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>../Dataset/test/abc_question_images/rain_shado...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>a diagram of the water cycle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climate and its causes</td>\n",
       "      <td>How does water from the clouds reach the land ...</td>\n",
       "      <td>ICE FROM THE MOUNTAIN PEAK</td>\n",
       "      <td>AS RAIN</td>\n",
       "      <td>WIND</td>\n",
       "      <td>GRASS</td>\n",
       "      <td>AS RAIN</td>\n",
       "      <td>../Dataset/test/abc_question_images/rain_shado...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>a diagram of the water cycle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>climate and its causes</td>\n",
       "      <td>What letter represents the condensation process?</td>\n",
       "      <td>W</td>\n",
       "      <td>J</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>../Dataset/test/abc_question_images/rain_shado...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>a diagram of the water cycle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climate and its causes</td>\n",
       "      <td>Where can you find moist air?</td>\n",
       "      <td>W</td>\n",
       "      <td>A</td>\n",
       "      <td>H</td>\n",
       "      <td>J</td>\n",
       "      <td>J</td>\n",
       "      <td>../Dataset/test/abc_question_images/rain_shado...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>a diagram of the water cycle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climate and its causes</td>\n",
       "      <td>Where is condensation?</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>T</td>\n",
       "      <td>../Dataset/test/abc_question_images/rain_shado...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>a diagram of the water cycle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lesson_name                                      question_name  \\\n",
       "0  climate and its causes                       Which label refers to rains?   \n",
       "1  climate and its causes  How does water from the clouds reach the land ...   \n",
       "2  climate and its causes   What letter represents the condensation process?   \n",
       "3  climate and its causes                      Where can you find moist air?   \n",
       "4  climate and its causes                             Where is condensation?   \n",
       "\n",
       "              answer_choice_1 answer_choice_2 answer_choice_3 answer_choice_4  \\\n",
       "0                           V               T               U               E   \n",
       "1  ICE FROM THE MOUNTAIN PEAK         AS RAIN            WIND           GRASS   \n",
       "2                           W               J               H               T   \n",
       "3                           W               A               H               J   \n",
       "4                           T               H               A               W   \n",
       "\n",
       "  correct_answer                                         image_path  \\\n",
       "0              E  ../Dataset/test/abc_question_images/rain_shado...   \n",
       "1        AS RAIN  ../Dataset/test/abc_question_images/rain_shado...   \n",
       "2              T  ../Dataset/test/abc_question_images/rain_shado...   \n",
       "3              J  ../Dataset/test/abc_question_images/rain_shado...   \n",
       "4              T  ../Dataset/test/abc_question_images/rain_shado...   \n",
       "\n",
       "  image_has_labels_to_guess                       caption  \\\n",
       "0                       Yes  a diagram of the water cycle   \n",
       "1                       Yes  a diagram of the water cycle   \n",
       "2                       Yes  a diagram of the water cycle   \n",
       "3                       Yes  a diagram of the water cycle   \n",
       "4                       Yes  a diagram of the water cycle   \n",
       "\n",
       "  blip_2_generated_answers  \n",
       "0                     None  \n",
       "1                     None  \n",
       "2                     None  \n",
       "3                     None  \n",
       "4                     None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_qa_df = pd.read_csv(\"../Dataset/test/DiagramQuestionsData.csv\")\n",
    "image_qa_df[\"blip_2_generated_answers\"] = None\n",
    "image_qa_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "image_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, question in enumerate(image_qa_df[\"question_name\"]):\n",
    "    if pd.isna(image_qa_df.loc[idx, \"blip_2_generated_answers\"]):\n",
    "        # Build answer choice string\n",
    "        answer_choice_1 = image_qa_df.loc[idx, \"answer_choice_1\"]\n",
    "        answer_choice_2 = image_qa_df.loc[idx, \"answer_choice_2\"]\n",
    "        answer_choice_3 = image_qa_df.loc[idx, \"answer_choice_3\"]\n",
    "        answer_choice_4 = image_qa_df.loc[idx, \"answer_choice_4\"]\n",
    "        answer_string = f\"\\na. {answer_choice_1}\\nb. {answer_choice_2}\\nc. {answer_choice_3}\\nd. {answer_choice_4}\"\n",
    "        \n",
    "        # prepare the image\n",
    "        raw_image = Image.open(image_qa_df.loc[idx, \"image_path\"]).convert(\"RGB\")\n",
    "        image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt = f\"\\nQuestion: {question} Choose only one option.\\n{answer_string}\\n\\nAnswer:\"\n",
    "        image_qa_df.loc[idx, \"blip_2_generated_answers\"] = model.generate({\"image\": image, \"prompt\": prompt})[0]\n",
    "        \n",
    "        # Continuously store answers in a CSV file in-case of a session timeout\n",
    "        image_qa_df.to_csv(\"blip2_answers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(filename):\n",
    "    blip2_answers = pd.read_csv(filename)\n",
    "    def map_predicted_to_actual(row):\n",
    "        if row['blip_2_generated_answers'] in ['a.', 'a']:\n",
    "            return row['answer_choice_1']\n",
    "        elif row['blip_2_generated_answers'] in ['b', 'b.']:\n",
    "            return row['answer_choice_2']\n",
    "        elif row['blip_2_generated_answers'] in ['c', 'c.']:\n",
    "            return row['answer_choice_3']\n",
    "        elif row['blip_2_generated_answers'] in ['d.', '(d)', 'd']:\n",
    "            return row['answer_choice_4']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    blip2_answers['mapped_predictions'] = blip2_answers.apply(map_predicted_to_actual, axis=1)\n",
    "    correct_blip2_preds = blip2_answers[blip2_answers[\"mapped_predictions\"].str.lower() == blip2_answers[\"correct_answer\"].str.lower()]\n",
    "    print(f\"Number of correct predictions: {len(correct_blip2_preds)} out of a total of {len(blip2_answers)} questions.\")\n",
    "    print(f\"Accuracy: {len(correct_blip2_preds) / len(blip2_answers) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 1805 out of a total of 3285 questions.\n",
      "Accuracy: 54.946727549467276\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for predictions where image descriptions are not provided\n",
    "get_predictions(\"blip2_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 212 out of a total of 403 questions.\n",
      "Accuracy: 52.605459057071954\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for predictions on a subset of images where image descriptions are provided.\n",
    "get_predictions(\"common_blip2_llava_gpt4_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
